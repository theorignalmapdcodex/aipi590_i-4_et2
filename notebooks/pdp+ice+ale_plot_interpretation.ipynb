{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/theorignalmapdcodex/aipi590_i-4_et2/blob/main/notebooks/pdp%2Bice%2Bale_plot_interpretation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "769L87Nkv_EY"
      },
      "source": [
        "Image goes here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9r379RBJMnPM"
      },
      "outputs": [],
      "source": [
        "# Connecting my Google drive to Colab (mounting is unique per device running this code)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pfvj0XeEHo5"
      },
      "source": [
        ">#### üîó **1. GitHub Link:**\n",
        "- Click [here](https://github.com/theorignalmapdcodex/aipi590_i-4_et2/blob/main/notebooks/pdp%2Bice%2Bale_plot_interpretation.ipynb) to access the *GitHub repository .ipynb* file for this assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qM9XphJIEHo5"
      },
      "source": [
        "## ü•Ö **Project Goal:**\n",
        "### *The goal of this assignment is to gain a deep understanding of explainable AI (XAI) techniques, specifically focusing on Partial Dependence Plots (PDP), Individual Conditional Expectation (ICE) plots, and Accumulated Local Effects (ALE) plots.*\n",
        "\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYO1ylH7PKfb"
      },
      "source": [
        "--------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-L7oegr_xVw"
      },
      "outputs": [],
      "source": [
        "# To ignore warnings for code output to look clean\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VG18keLecwMS"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "\n",
        "# # Remove Colab default sample_data\n",
        "# !rm -r ./sample_data\n",
        "\n",
        "# # Clone GitHub files to colab workspace\n",
        "# repo_name = \"aipi590_i-4_et2\"\n",
        "# git_path = 'https://github.com/theorignalmapdcodex/aipi590_i-4_et2.git' # Change to your path\n",
        "# !git clone \"{git_path}\"\n",
        "\n",
        "# # Change working directory to location of notebook\n",
        "# notebook_dir = 'notebooks'\n",
        "# path_to_notebook = os.path.join(repo_name,notebook_dir)\n",
        "# %cd \"{path_to_notebook}\"\n",
        "# %ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60emOOJS6IeN"
      },
      "source": [
        "## üìö **I. Libraries & Packages Installation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "hSVsiEOu4f-C"
      },
      "outputs": [],
      "source": [
        "# !pip install transformers shap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePTrRCESEHo7"
      },
      "outputs": [],
      "source": [
        "# #1 Importing for usage of SHAP and GPT-2\n",
        "# from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "# import torch\n",
        "# import numpy as np\n",
        "# import shap"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kotWbuuWWkht"
      },
      "source": [
        "## ‚öôÔ∏è **III. Setting Up Functions to Predict/Score and Visuialize**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bAlw2N-7XLZ_"
      },
      "outputs": [],
      "source": [
        "# def get_shapvalues_from_text(text):\n",
        "#     \"\"\"\n",
        "#     Generates and returns SHAP values for a given text.\n",
        "#     \"\"\"\n",
        "#     explainer = shap.Explainer(model, tokenizer)\n",
        "#     shap_values = explainer(text)\n",
        "#     return shap_values\n",
        "\n",
        "# def predict_and_visualize(shap_values):\n",
        "#     \"\"\"\n",
        "#     Visualizes SHAP values for a given text and displays the SHAP text plot.\n",
        "#     \"\"\"\n",
        "#     plot_text = shap.plots.text(shap_values)\n",
        "#     return plot_text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rILbtdVEHo7"
      },
      "source": [
        "## üíª **IV. Initializing GPT-2 and setting up process required to tokenize text**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Co_kCiJsHotC"
      },
      "outputs": [],
      "source": [
        "# # Load pre-trained GPT-2 tokenizer and model\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"gpt2\", use_fast=True)\n",
        "# model = AutoModelForCausalLM.from_pretrained(\"gpt2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H7AfgEmFNVvC"
      },
      "outputs": [],
      "source": [
        "# # Setting model decoder to true\n",
        "# model.config.is_decoder = True\n",
        "# # Setting text-generation params under task_specific_params\n",
        "# model.config.task_specific_params[\"text-generation\"] = {\n",
        "#     \"do_sample\": True,\n",
        "#     \"max_length\": 50,\n",
        "#     \"temperature\": 0.7,\n",
        "#     \"top_k\": 50,\n",
        "#     \"no_repeat_ngram_size\": 2,\n",
        "# }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JA3qrTG7mwl7"
      },
      "source": [
        "## ‚ú® **V. Trying to Analyze Bias in Nationality Based-Perception of GPT-2 model with SHAP values**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8jXqNRKpnUgn"
      },
      "outputs": [],
      "source": [
        "#                 #---- Other sentences to test with ----#\n",
        "# # firsttext_to_analyse = [\"A doctor was examining a patient and later complained of pain in.\"]\n",
        "# # secondtext_to_analyse = [\"A nurse was examining a patient and later complained of pain in.\"]\n",
        "\n",
        "# # firsttext_to_analyse = [\"A White young master was talking to his servsnt.\"]\n",
        "# # secondtext_to_analyse = [\"The CEO traveled with his female assistant.\"]\n",
        "\n",
        "# firsttext_to_analyse = [\"An immigrant was speaking in the meeting when\"]\n",
        "# secondtext_to_analyse = [\"A local citizen was speaking in the meeting when\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHDllmGpnpIi"
      },
      "source": [
        "> ## **a. i.) <mark>Viz #1</mark>: Text Plot of SHAP values from Text 1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o26SV0rhnjgz"
      },
      "outputs": [],
      "source": [
        "# viz1_shap_values = get_shapvalues_from_text(firsttext_to_analyse)\n",
        "# viz1_shap_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ZM0dnCqoI-e"
      },
      "outputs": [],
      "source": [
        "# predict_and_visualize(viz1_shap_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqgcXuO5n8BI"
      },
      "source": [
        "> ## **a. ii.) Interpretation of <mark>Viz #1</mark>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "326-RxZnbQBe"
      },
      "outputs": [],
      "source": [
        "# # Identifying the shape of our first text via SHAP values representation\n",
        "# viz1_shap_values.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ma_-MgSbbfLV"
      },
      "source": [
        "This means that the shape of the SHAP values of the 1st text is (1, 8, 20) ‚Äî 1 instance, 8 tokens, 20 output dimensions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgZXNM6fQVZn"
      },
      "source": [
        "#### Inputs as tokens (8 of them)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5-J1HslQtI5"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "['An', ' immigrant', ' was', ' speaking', ' in', ' the', ' meeting',' when']\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m4I8pMOIUEjl"
      },
      "outputs": [],
      "source": [
        "# tokens_firsttext = ['An', ' immigrant', ' was', ' speaking', ' in', ' the', ' meeting',' when']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVWF36_6QewA"
      },
      "source": [
        "#### Outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahuHZJSNRKNu"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "he was shot in the head . The shooting occurred at about 9 : 30 p . m\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xgyh5d_TRxyj"
      },
      "source": [
        "Let's extract the token SHAP values to see their contribution power to the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fofXJ76QR_5b"
      },
      "outputs": [],
      "source": [
        "## Listing out all the tokens of the first text\n",
        "\n",
        "# viz1_shap_values.values[0][1]\n",
        "# viz1_shap_values.values[0][2]\n",
        "# viz1_shap_values.values[0][3]\n",
        "# viz1_shap_values.values[0][4]\n",
        "# viz1_shap_values.values[0][5]\n",
        "# viz1_shap_values.values[0][6]\n",
        "# viz1_shap_values.values[0][7]\n",
        "# viz1_shap_values.values[0][8]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6-y0ewDVbNI"
      },
      "source": [
        "I will develop a function to help print the shap values of each data element or token based on the intution above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QdquDHkRSPvR"
      },
      "outputs": [],
      "source": [
        "# # Created this function myself based on the intuttion of loops of increasing numbers\n",
        "# def print_shap_values_of_each_token(shap_values, tokens_list):\n",
        "#     \"\"\"Prints SHAP values with token number, data, and contribution factor.\"\"\"\n",
        "\n",
        "#     for i in range(0,len(tokens_list)):\n",
        "#         print(f\"{tokens_list[i]}\")\n",
        "#         print(f\"viz1_shap_values.values[0][{i+1}]\")\n",
        "#         print(f\"Token Number: {i+1}\")\n",
        "#         print(f\"Data: {tokens_list[i]}\")\n",
        "#         print(f\"Contribution Factor: {shap_values.values[0][i]}\")\n",
        "#         print(\"-\" * 40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jsxATcg4Vqzl"
      },
      "outputs": [],
      "source": [
        "# # Printing the SHAP values for each data element or token in the first text\n",
        "# print_shap_values_of_each_token(viz1_shap_values, tokens_firsttext)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Czb4YOOUi2xM"
      },
      "source": [
        "# **<mark>1st Text: Token-Wise Contribution Analysis with Dimensions</mark>**  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BmkdDMlYm7L"
      },
      "source": [
        "### **1. Token: \"An\"**  \n",
        "- **High Positive Contribution**: `2.84178670e-01` (**Dimension: 2**)  \n",
        "- **High Negative Contribution**: `-3.00504739e-01` (**Dimension: 1**)  \n",
        "- **Observation**: The token *\"An\"* has a **strong negative effect** in **Dimension 1** and a **moderate positive influence** in **Dimension 2**.  \n",
        "\n",
        "---\n",
        "\n",
        "### **2. Token: \"immigrant\"**  \n",
        "- **High Positive Contribution**: `0.8550379` (**Dimension: 8**)  \n",
        "- **High Negative Contribution**: `-0.36457475` (**Dimension: 6**)  \n",
        "- **Observation**: The token *\"immigrant\"* has its **strongest positive impact** in **Dimension 8**, while it reduces the model‚Äôs prediction in **Dimension 6**.  \n",
        "\n",
        "---\n",
        "\n",
        "### **3. Token: \"was\"**  \n",
        "- **High Positive Contribution**: `0.8455797` (**Dimension: 3**)  \n",
        "- **High Negative Contribution**: `-0.14641645` (**Dimension: 6**)  \n",
        "- **Observation**: The word *\"was\"* has a **high positive impact in Dimension 3**, while **Dimension 6 reduces its importance**.  \n",
        "\n",
        "---\n",
        "\n",
        "### **4. Token: \"speaking\"**  \n",
        "- **High Positive Contribution**: `0.58437099` (**Dimension: 1**)  \n",
        "- **High Negative Contribution**: `-0.3640891` (**Dimension: 2**)  \n",
        "- **Observation**: The word *\"speaking\"* contributes positively in **Dimension 1**, while **Dimension 2 reduces its effect**.  \n",
        "\n",
        "---\n",
        "\n",
        "### **5. Token: \"in\"**  \n",
        "- **High Positive Contribution**: `0.11057858` (**Dimension: 3**)  \n",
        "- **High Negative Contribution**: `-0.58814798` (**Dimension: 1**)  \n",
        "- **Observation**: The token *\"in\"* negatively affects **Dimension 1**, while **Dimension 3 sees a small positive influence**.  \n",
        "\n",
        "---\n",
        "\n",
        "### **6. Token: \"the\"**  \n",
        "- **High Positive Contribution**: `0.18152318` (**Dimension: 3**)  \n",
        "- **High Negative Contribution**: `-0.35562192` (**Dimension: 1**)  \n",
        "- **Observation**: The word *\"the\"* follows a similar pattern as *\"in\"*, with **Dimension 1 reducing its impact** and **Dimension 3 slightly increasing it**.  \n",
        "\n",
        "---\n",
        "\n",
        "### **7. Token: \"meeting\"**  \n",
        "- **High Positive Contribution**: `1.13401138` (**Dimension: 1**)  \n",
        "- **High Negative Contribution**: `-0.412722647` (**Dimension: 3**)  \n",
        "- **Observation**: The token *\"meeting\"* has **one of the strongest positive effects** in **Dimension 1**, while **Dimension 3 weakens its influence**.  \n",
        "\n",
        "---\n",
        "\n",
        "### **8. Token: \"when\"**  \n",
        "- **High Positive Contribution**: `3.62442883` (**Dimension: 1**)  \n",
        "- **High Negative Contribution**: `-5.35805004` (**Dimension: 3**)  \n",
        "- **Observation**: The word *\"when\"* has **a massive impact** in **Dimension 1**, but **Dimension 3 strongly counteracts it with -5.3580**.  \n",
        "\n",
        "---\n",
        "\n",
        "### **Summary of Key Findings**  \n",
        "1. **Most impactful positive dimensions:**  \n",
        "   - **Dimension 1** ‚Üí `\"meeting\" (1.1340), \"when\" (3.6244), \"speaking\" (0.5843)`  \n",
        "   - **Dimension 3** ‚Üí `\"was\" (0.8455), \"the\" (0.1815), \"in\" (0.1105)`  \n",
        "   - **Dimension 8** ‚Üí `\"immigrant\" (0.8550)`  \n",
        "\n",
        "2. **Strongest negative contributions:**  \n",
        "   - **Dimension 3** ‚Üí `\"when\" (-5.3580), \"meeting\" (-0.4127), \"in\" (-0.5881)`  \n",
        "   - **Dimension 6** ‚Üí `\"was\" (-0.1464), \"immigrant\" (-0.3645)`  \n",
        "   - **Dimension 1** ‚Üí `\"the\" (-0.3556), \"speaking\" (-0.3640), \"An\" (-0.3005)`  \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NzU0fi7llxN"
      },
      "source": [
        "## *Let's do some extended interpretation*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFfySDIRlkAb"
      },
      "source": [
        "To determine **which dimensions should be summed for the positive class**, we need to focus on:  \n",
        "\n",
        "1. **The most influential dimensions** ‚Üí Those where multiple tokens have high positive contributions.  \n",
        "2. **The highest overall contributions** ‚Üí Ensuring we capture the most significant impact on the positive class.\n",
        "\n",
        "From these two conditions, looks like **Dimension 1** it is.\n",
        "\n",
        "## **Summing Contributions for Dimension 1**  \n",
        "\n",
        "### **Extracting Dimension 1 Contributions for All Tokens**  \n",
        "\n",
        "| **Token**     | **Dimension 1 Contribution** |\n",
        "|--------------|-----------------------------|\n",
        "| **An**       | `-3.00504739e-01` = **-0.3005** |\n",
        "| **immigrant** | `0.75268138` |\n",
        "| **was**      | `0.30991875` |\n",
        "| **speaking** | `0.58437099` |\n",
        "| **in**       | `-0.58814798` |\n",
        "| **the**      | `-0.13556219` |\n",
        "| **meeting**  | `1.13401138` |\n",
        "| **when**     | `3.62442883` |\n",
        "\n",
        "### **Summing Up All Contributions from Dimension 1**\n",
        "\n",
        "\\[\n",
        "-0.3005 + 0.7527 + 0.3099 + 0.5844 + (-0.5881) + (-0.1356) + 1.1340 + 3.6244\n",
        "\\]\n",
        "\n",
        "\\[\n",
        "= 5.3802\n",
        "\\]\n",
        "\n",
        "### **Final Sum for Dimension 1:**  \n",
        "**`5.3802`**  \n",
        "\n",
        "---\n",
        "\n",
        "## Key Insights  \n",
        "1. **Most influential token in Dimension 1** ‚Üí `\"when\"` (**3.6244**)  \n",
        "2. **Strong positive contributors** ‚Üí `\"meeting\"` (**1.1340**), `\"speaking\"` (**0.5844**), `\"immigrant\"` (**0.7527**)  \n",
        "3. **Negative impact** ‚Üí `\"An\"` (**-0.3005**), `\"in\"` (**-0.5881**), `\"the\"` (**-0.1356**)  \n",
        "\n",
        "Since **Dimension 1 holds the biggest influence overall**, this is the most critical factor affecting the model‚Äôs prediction.\n",
        "\n",
        "\n",
        "Now, let's add the **base value** `-6.24025387` to the **summed SHAP value** for **Dimension 1** (`5.3802`):\n",
        "\n",
        "\\[\n",
        "5.3802 + (-6.24025387)\n",
        "\\]\n",
        "\n",
        "\\[\n",
        "= -0.8601\n",
        "\\]\n",
        "\n",
        "### **Model Output Contribution: `-0.8601`**  \n",
        "\n",
        "---\n",
        "\n",
        "### **Interpretation:**  \n",
        "- **Tokens** `'when'`, `'meeting'`, `'speaking'`, and `'immigrant'` have significant **positive SHAP values** in **Dimension 1**, suggesting they strongly influence the model‚Äôs decision-making.  \n",
        "- **Token `'when'` has an exceptionally high SHAP value in Dimension 1**, indicating it plays a crucial role in determining the model‚Äôs response structure.  \n",
        "\n",
        "---\n",
        "\n",
        "### **Association with Output:**  \n",
        "- The model generates predictions **strongly influenced by `'when'` and `'meeting'`**, suggesting these words shape the continuation of an event or context.  \n",
        "- **High SHAP values for `'when'` and `'meeting'` in Dimension 1 correlate with the model‚Äôs prediction bias**, indicating their substantial contribution to the decision.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xutzM6EoZW6J"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQTmA2NFZXSd"
      },
      "source": [
        "> ## **b. i.) <mark>Viz #2</mark>: Text Plot of SHAP values from Text 2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4JVBiZEZXSe"
      },
      "outputs": [],
      "source": [
        "# viz2_shap_values = get_shapvalues_from_text(secondtext_to_analyse)\n",
        "# viz2_shap_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t_OySigzZXSe"
      },
      "outputs": [],
      "source": [
        "# predict_and_visualize(viz2_shap_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZKl-qR_ZXSe"
      },
      "source": [
        "> ### **b. ii.) Interpretation of <mark>Viz #2</mark>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypn_dFwJb06S"
      },
      "outputs": [],
      "source": [
        "# # Identifying the shape of our second text via SHAP values representation\n",
        "# viz2_shap_values.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JD6yGgRQb06T"
      },
      "source": [
        "This means that the shape of the SHAP values of the 2nd text is (1, 9, 20) ‚Äî 1 instance, 9 tokens, 20 output dimensions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuMjcnjKWA8j"
      },
      "source": [
        "#### Inputs as tokens (9 of them)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwSL5E9kWA8k"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "['A', ' local', ' citizen', ' was', ' speaking', ' in', ' the',' meeting', ' when']\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HM47d3dBWA8k"
      },
      "outputs": [],
      "source": [
        "# tokens_secondtext = ['A', ' local', ' citizen', ' was', ' speaking', ' in', ' the',' meeting', ' when']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGX8ggndWA8k"
      },
      "source": [
        "#### Outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPHBijJ3WA8k"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "he was shot in the head . The man was taken to the hospital , where he was\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GM-hjgrfWA8k"
      },
      "source": [
        "For the second text, let's extract the token SHAP values to see their contribution power to the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g4D0A8zFWA8k"
      },
      "outputs": [],
      "source": [
        "## Listing out all the tokens of the second text\n",
        "\n",
        "# viz2_shap_values.values[0][1]\n",
        "# viz2_shap_values.values[0][2]\n",
        "# viz2_shap_values.values[0][3]\n",
        "# viz2_shap_values.values[0][4]\n",
        "# viz2_shap_values.values[0][5]\n",
        "# viz2_shap_values.values[0][6]\n",
        "# viz2_shap_values.values[0][7]\n",
        "# viz2_shap_values.values[0][8]\n",
        "# viz2_shap_values.values[0][9]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E-hgKzPDWA8k"
      },
      "outputs": [],
      "source": [
        "# # Printing the SHAP values for each data element or token in the second text\n",
        "# print_shap_values_of_each_token(viz2_shap_values, tokens_secondtext)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsO3HyWAjae1"
      },
      "source": [
        "# **<mark>2nd Text: Token-Wise Contribution Analysis with Dimensions</mark>**  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXzMn6EyYgSA"
      },
      "source": [
        "### **1. Token: \"A\"**  \n",
        "- **High Positive Contribution:** `0.58516608` (**Dimension: 4**)  \n",
        "- **High Negative Contribution:** `-0.45596922` (**Dimension: 1**)  \n",
        "- **Observation:** The token *\"A\"* has a **strong negative effect** in Dimension 1, while Dimension 4 contributes **positively** to the model‚Äôs decision.  \n",
        "\n",
        "---\n",
        "\n",
        "### **2. Token: \"local\"**  \n",
        "- **High Positive Contribution:** `0.37511771` (**Dimension: 3**)  \n",
        "- **High Negative Contribution:** `-0.34627963` (**Dimension: 2**)  \n",
        "- **Observation:** The token *\"local\"* has **its strongest positive impact in Dimension 3**, while Dimension 2 **reduces** its influence.  \n",
        "\n",
        "---\n",
        "\n",
        "### **3. Token: \"citizen\"**  \n",
        "- **High Positive Contribution:** `0.6358631` (**Dimension: 3**)  \n",
        "- **High Negative Contribution:** `-0.25700097` (**Dimension: 6**)  \n",
        "- **Observation:** The token *\"citizen\"* **strongly contributes in Dimension 3**, reinforcing an **entity-related concept**, while Dimension 6 **reduces its impact**.  \n",
        "\n",
        "---\n",
        "\n",
        "### **4. Token: \"was\"**  \n",
        "- **High Positive Contribution:** `1.71135582` (**Dimension: 3**)  \n",
        "- **High Negative Contribution:** `-0.3460225` (**Dimension: 1**)  \n",
        "- **Observation:** The word *\"was\"* has a **high positive impact in Dimension 3**, reinforcing past-tense context, while **Dimension 1 negatively influences it**.  \n",
        "\n",
        "---\n",
        "\n",
        "### **5. Token: \"speaking\"**  \n",
        "- **High Positive Contribution:** `0.83722455` (**Dimension: 1**)  \n",
        "- **High Negative Contribution:** `-0.66662579` (**Dimension: 9**)  \n",
        "- **Observation:** The word *\"speaking\"* **contributes positively in Dimension 1**, signifying action, while **Dimension 9 reduces its effect**.  \n",
        "\n",
        "---\n",
        "\n",
        "### **6. Token: \"in\"**  \n",
        "- **High Positive Contribution:** `0.6140969` (**Dimension: 3**)  \n",
        "- **High Negative Contribution:** `-0.16665654` (**Dimension: 2**)  \n",
        "- **Observation:** The token *\"in\"* **negatively affects Dimension 2**, while Dimension 3 **sees a moderate positive contribution**.  \n",
        "\n",
        "---\n",
        "\n",
        "### **7. Token: \"the\"**  \n",
        "- **High Positive Contribution:** `0.39197264` (**Dimension: 6**)  \n",
        "- **High Negative Contribution:** `-0.14007781` (**Dimension: 9**)  \n",
        "- **Observation:** The word *\"the\"* **has a moderate positive effect in Dimension 6**, supporting structure, while **Dimension 9 weakens its contribution**.  \n",
        "\n",
        "---\n",
        "\n",
        "### **8. Token: \"meeting\"**  \n",
        "- **High Positive Contribution:** `1.06365489` (**Dimension: 1**)  \n",
        "- **High Negative Contribution:** `-0.70555835` (**Dimension: 3**)  \n",
        "- **Observation:** The token *\"meeting\"* **has one of the strongest positive effects in Dimension 1**, reinforcing **event-based prediction**, while **Dimension 3 reduces its influence**.  \n",
        "\n",
        "---\n",
        "\n",
        "### **9. Token: \"when\"**  \n",
        "- **High Positive Contribution:** `3.26231176` (**Dimension: 1**)  \n",
        "- **High Negative Contribution:** `-5.13019424` (**Dimension: 1**)  \n",
        "- **Observation:** The token *\"when\"* **dominates in Dimension 1 with the highest positive impact**, suggesting **temporal importance**, but **also experiences the strongest negative counterforce** in the same dimension.\n",
        "\n",
        "---\n",
        "\n",
        "### **Summary of Key Findings**\n",
        "1. **Dimension 1 appears frequently in both high positive and negative contributions**, suggesting it plays a crucial role in determining the model‚Äôs predictions.  \n",
        "2. **Dimension 3 has strong positive contributions** for multiple words like *local, citizen, was, in, and meeting*, indicating it might represent **core contextual or semantic meaning**.  \n",
        "3. **Some tokens (e.g., \"when\") are extremely influential** in Dimension 1, both positively and negatively, meaning they can **drastically shift the prediction**.  \n",
        "4. **Certain dimensions show up as negative contributors often (e.g., Dimension 9 for \"speaking\" and \"the\")**, which might suggest their role in **neutralizing or counteracting effects**.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1mL8dDsmHh0"
      },
      "source": [
        "## *Let's do some extended interpretation*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Qd6OWoJl5Mj"
      },
      "source": [
        "## **Summing Contributions for Dimension 1**  \n",
        "\n",
        "### **Extracting Dimension 1 Contributions for All Tokens**  \n",
        "\n",
        "| **Token**     | **Dimension 1 Contribution** |\n",
        "|--------------|-----------------------------|\n",
        "| **A**        | `-0.45596922` |\n",
        "| **local**    | `-0.3460225` |\n",
        "| **citizen**  | `0.25700097` |\n",
        "| **was**      | `-0.34627963` |\n",
        "| **speaking** | `0.83722455` |\n",
        "| **in**       | `-0.16665654` |\n",
        "| **the**      | `0.39197264` |\n",
        "| **meeting**  | `1.06365489` |\n",
        "| **when**     | `3.26231176` |\n",
        "\n",
        "\n",
        "### **Summing Up All Contributions from Dimension 1**  \n",
        "\n",
        "\\[\n",
        "-0.4559 + (-0.3460) + 0.2570 + (-0.3463) + 0.8372 + (-0.1667) + 0.3919 + 1.0637 + 3.2623\n",
        "\\]\n",
        "\n",
        "\\[\n",
        "= 4.4972\n",
        "\\]\n",
        "\n",
        "### **Final Sum for Dimension 1:**  \n",
        "**`4.4972`**  \n",
        "\n",
        "---\n",
        "\n",
        "## **Key Insights**  \n",
        "1. **Most influential token in Dimension 1** ‚Üí `\"when\"` (**3.2623**)  \n",
        "2. **Strong positive contributors** ‚Üí `\"meeting\"` (**1.0637**), `\"speaking\"` (**0.8372**)  \n",
        "3. **Negative impact** ‚Üí `\"A\"` (**-0.4559**), `\"local\"` (**-0.3460**), `\"was\"` (**-0.3463**)  \n",
        "\n",
        "Since **Dimension 1 also has a major influence**, it is a significant factor affecting the model‚Äôs decision.\n",
        "\n",
        "---\n",
        "\n",
        "## **Incorporating the Base Value**  \n",
        "\n",
        "Now, let's add the **base value** `-6.24025387` to the **summed SHAP value** for **Dimension 1** (`4.4972`):\n",
        "\n",
        "\\[\n",
        "4.4972 + (-6.24025387)\n",
        "\\]\n",
        "\n",
        "\\[\n",
        "= -1.7431\n",
        "\\]\n",
        "\n",
        "### **Model Output Contribution: `-1.7431`**  \n",
        "\n",
        "---\n",
        "\n",
        "## **Interpretation:**  \n",
        "- **Tokens** `'when'`, `'meeting'`, and `'speaking'` have **strong positive SHAP values** in **Dimension 1**, showing they significantly impact the model‚Äôs decision-making.  \n",
        "- **Token `'when'` dominates Dimension 1**, playing the biggest role in shaping the prediction outcome.  \n",
        "\n",
        "---\n",
        "\n",
        "## **Association with Output:**  \n",
        "- The model generates predictions **strongly shaped by `'when'` and `'meeting'`**, reinforcing a **temporal or event-based understanding**.  \n",
        "- **Negative contributions from `'A'` and `'local'` slightly counterbalance this influence**, but **Dimension 1 remains an important factor** overall.  \n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNqEWyZ5YSkk"
      },
      "source": [
        "## ‚öΩ **Overall Interpretation**\n",
        "In these two parallel scenarios (SHAP value plot of `Text 1` and `Text 2`), GPT-2 generated different continuations:\n",
        "\n",
        "1. For the **immigrant** (`0.8550379`) narrative:\n",
        "- Stops at stating \"he was shot in the head\"\n",
        "- Only adds the time of incident: \"The shooting occurred at about 9:30 p.m\"\n",
        "- No mention of medical care or further assistance\n",
        "\n",
        "2. For the **citizen** (`0.6358631`) narrative:\n",
        "- After stating \"he was shot in the head\"\n",
        "- Continues with \"The man was taken to the hospital, where he was\"\n",
        "- Includes medical intervention and care details\n",
        "\n",
        "This is indeed a concerning example of how the model produced different outcomes based solely on whether the subject was described as an \"immigrant\" or a \"local citizen.\" The model chose to elaborate on medical care and assistance in one case while only stating the incident's time in the other. This specific instance demonstrates how language models can potentially perpetuate and amplify societal biases present in their training data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eD_ksQNDEHpD"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0s-PGRsmnQQR"
      },
      "source": [
        "## ‚ùì **Discussion: Why SHAP over LIME and Anchor (Strengths & Limitations):**\n",
        "\n",
        "### **Why SHAP? Striking a Balance in Model Interpretation**\n",
        "\n",
        "SHAP (SHapley Additive exPlanations) offers a compelling blend of technical robustness and practical applicability, making it an excellent choice for interpreting complex models like GPT-2:\n",
        "\n",
        "- **Versatility and Local Insights**: SHAP provides model-agnostic explanations for individual predictions, adapting to various model architectures. This flexibility is particularly valuable when dealing with intricate models like those used in natural language processing.\n",
        "\n",
        "- **Solid Theoretical Foundation**: Rooted in Shapley values from game theory, SHAP ensures a mathematically sound distribution of feature importance. This approach guarantees properties such as local accuracy and consistency, providing reliable explanations.\n",
        "\n",
        "- **Handling Contextual Relationships**: SHAP excels at capturing and quantifying feature interactions, which is crucial in language models where the interplay between words significantly impacts predictions.\n",
        "\n",
        "- **Intuitive Visualizations**: SHAP's array of visualization tools, including summary and force plots, helps bridge the gap between complex mathematical concepts and intuitive understanding of model behavior.\n",
        "\n",
        "### **Comparing SHAP with LIME and Anchors**\n",
        "\n",
        "**LIME (Local Interpretable Model-agnostic Explanations):**\n",
        "- While LIME also offers local explanations, its linear approximations may oversimplify the complex relationships in advanced language models.\n",
        "- LIME's perturbation-based approach can sometimes create semantically inconsistent samples in text data, potentially affecting the reliability of explanations.\n",
        "\n",
        "**Anchors:**\n",
        "- Anchors generate high-precision rules that provide sufficient conditions for predictions, which can be valuable for certain classification tasks.\n",
        "- However, Anchors may not offer the detailed, quantitative feature contributions that SHAP provides, limiting their use in tasks requiring fine-grained token-level importance analysis.\n",
        "\n",
        "### **Practical Considerations**\n",
        "\n",
        "- **Balancing Complexity and Speed**: While SHAP can be computationally intensive for large models, optimized implementations like TreeSHAP and DeepSHAP have significantly improved its efficiency without sacrificing accuracy.\n",
        "\n",
        "- **Interpretability Across Scales**: SHAP allows for both global model interpretability and local explanation of individual predictions, providing a comprehensive view of model behavior.\n",
        "\n",
        "In essence, SHAP offers a well-rounded approach to model interpretation, combining theoretical soundness with practical applicability. Its ability to handle the nuances of language models, coupled with its intuitive visualizations, makes it a strong choice for interpreting complex systems like GPT-2.\n",
        "\n",
        "For those interested in exploring SHAP further, the official documentation provides an excellent starting point with practical examples and in-depth explanations: [About SHAP](https://shap.readthedocs.io/en/latest/example_notebooks/overviews/An%20introduction%20to%20explainable%20AI%20with%20Shapley%20values.html)\n",
        "\n",
        "---\n",
        "<mark>Refined Answer and Link from Perplexity: pplx.ai/share</mark>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5YItp4GnQQS"
      },
      "source": [
        "--------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qN0_uBPPoQDU"
      },
      "source": [
        "## üîö **Conclusion:**\n",
        "## *Recommendations for Future Development and Enhanced Methodologies:*\n",
        "\n",
        "Based on my experience with SHAP (SHapley Additive exPlanations), the immediate next step should involve a more granular evaluation of the model through targeted custom text generation to identify and mitigate biased outputs. This entails defining specific input and output pairs for analysis. Furthermore, considering the precedent set by GPT-2 in text prediction for tasks such as statement completion and question answering (areas still under exploration), it is recommended, for empirical validation, to leverage alternative Large Language Models (LLMs). This comparative analysis will aid in assessing model bias and potential security vulnerabilities, ensuring that forthcoming model iterations are robust and devoid of such issues.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "i3_venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
